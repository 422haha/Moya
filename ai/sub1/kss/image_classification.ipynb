{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 목표\n",
    "\n",
    "1. PyTorch를 이용한 딥러닝 모델 구축 및 학습 방법 이해\n",
    "2. Fully connected network와 CNN 모델의 이해\n",
    "3. 이미지 분류기 구축 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 실습에서 사용할 라이브러리를 import 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모델은 매우 큰 행렬 연산을 빠르게 수행해야 합니다. 때문에 CPU만으로는 연산이 느리거나 불가능한 경우가 많습니다. 따라서 GPU를 주로 사용합니다. 아래 `set_device` 함수는 디바이스를 설정합니다.\n",
    "\n",
    "> 🪄 Colab에서 GPU를 사용하려면 우측 상단의 '추가 연결 옵션'(RAM, 디스크 statistic 옆 화살표 버튼)에서 [런타임 유형 변경] - [하드웨어 가속기] 에서 GPU로 옵션을 변경해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(use_gpu):\n",
    "    \"\"\"Set the device to run the code.\n",
    "\n",
    "    Choose CUDA (GPU) if you want to use & it is available,\n",
    "    if not, choose CPU.\n",
    "\n",
    "    Args:\n",
    "        use_gpu (bool): whether you want to use GPU\n",
    "    Returns:\n",
    "        Torch.device: device to use in the code\n",
    "    \"\"\"\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(f\"Using Device: {device}\")\n",
    "    return device\n",
    "\n",
    "# Test the function\n",
    "device = set_device(use_gpu=\"True\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 본 실습에 사용할 설정 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_gpu=True,\n",
    "        lr=1e-2,\n",
    "        epoch=5,\n",
    "        log_interval=100,\n",
    "        dataset_path='./datasets',\n",
    "        image_size=32,\n",
    "        num_train_data=49000,\n",
    "        batch_size=64,\n",
    "        mlp_hidden_dim=512,\n",
    "        cnn_in_channel=3,\n",
    "        cnn_channel1=12,\n",
    "        cnn_channel2=8,\n",
    "    ):\n",
    "        # 모델 학습 관련 설정\n",
    "        self.use_gpu = use_gpu # GPU 사용 여부\n",
    "        self.lr = lr # learning rate\n",
    "        self.epoch = epoch # epoch 수\n",
    "        self.log_interval = log_interval # 실행 상황을 출력할 빈도\n",
    "\n",
    "        # 데이터셋 설정\n",
    "        self.dataset_path = dataset_path # 데이터셋을 다운받을 위치\n",
    "        self.classes = ( # 클래스 종류\n",
    "            'plane', 'car', 'bird', 'cat','deer',\n",
    "            'dog', 'frog', 'horse', 'ship', 'truck',\n",
    "        )\n",
    "        self.num_classes = len(self.classes) # 클래스 개수\n",
    "        self.image_size = image_size # 이미지의 가로/세로 크기\n",
    "\n",
    "        # 데이터 로더 설정\n",
    "        self.num_train_data = num_train_data # training set으로 사용할 이미지 개수\n",
    "        self.batch_size = batch_size # 한 배치 당 이미지 개수. GPU 성능이 낮을 경우 더 낮게 설정. 보통 2의 제곱수.\n",
    "\n",
    "        # FCN 사용 시 설정\n",
    "        self.mlp_input_size = self.image_size * self.image_size * 3 # MLP 입력 크기\n",
    "        self.mlp_hidden_dim = mlp_hidden_dim # MLP hidden layers의 데이터 차원\n",
    "\n",
    "        # CNN 사용 시 설정\n",
    "        self.cnn_in_channel = cnn_in_channel # CNN 입력 채널 수\n",
    "        self.cnn_channel1 = cnn_channel1 # CNN 은닉층1 채널 수\n",
    "        self.cnn_channel2 = cnn_channel2 # CNN 은닉층2 채널 수\n",
    "\n",
    "        # 실행 디바이스 설정\n",
    "        self.device = set_device(self.use_gpu)\n",
    "\n",
    "        # 데이터셋 다운로드 폴더 생성\n",
    "        if not os.path.exists(self.dataset_path):\n",
    "            os.makedirs(self.dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 내 데이터를 시각화하는 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0~255 사이의 픽셀값을 가지는 이미지 데이터를 모델이 처리할 수 있도록 텐서로 변경하고 [-1, 1] 범위로 픽셀 값을 정규화하는 data transformation을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(), # 텐서화\n",
    "        T.Normalize(  # 정규화 (각 채널의 mean과 std를 지정)\n",
    "            mean = (0.5, 0.5, 0.5),\n",
    "            std  = (0.5, 0.5, 0.5),\n",
    "        ),\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 데이터셋을 다운받아 가져오고, 데이터로더를 선언해 데이터를 가져오는 방식을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(dataset_path, batch_size, transform):\n",
    "    # Dataset split\n",
    "    cifar10_train = torchvision.datasets.CIFAR10(\n",
    "        dataset_path, train=True, download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    cifar10_val = torchvision.datasets.CIFAR10(\n",
    "        dataset_path, train=True, download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    cifar10_test = torchvision.datasets.CIFAR10(\n",
    "        dataset_path, train=False, download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    # Dataloader\n",
    "    loader_train = DataLoader(\n",
    "        dataset    = cifar10_train,\n",
    "        batch_size = batch_size,\n",
    "        shuffle    = True, # 데이터셋 내 데이터를 가져오는 순서를 섞음\n",
    "        drop_last  = True, # 맨 마지막 배치가 배치 크기에 맞지 않을 경우 버림\n",
    "    )\n",
    "\n",
    "    loader_val = DataLoader(\n",
    "        dataset    = cifar10_val,\n",
    "        batch_size = batch_size,\n",
    "        shuffle    = True,\n",
    "    )\n",
    "\n",
    "    loader_test = DataLoader(\n",
    "        dataset    = cifar10_test,\n",
    "        batch_size = batch_size,\n",
    "        shuffle    = False,\n",
    "    )\n",
    "\n",
    "    return loader_train, loader_val, loader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가져온 데이터셋 내 데이터가 어떻게 생겼는지 보기 위하여, 시각화 함수를 만들어보겠습니다.\n",
    "\n",
    "앞서 이미지를 텐서로 만들고 정규화하는 transformation을 거쳤는데, 시각화를 위해서는 이를 다시 되돌려야합니다. 또한 화면에 띄우는 작업도 필요합니다. 이 과정을 수행하는 함수 `visualize()`를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-1: 데이터셋 내 데이터를 시각화하는 함수 구현                             #\n",
    "############################################################################\n",
    "def visualize(img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img (torch.Tensor): A image to visualize, shape: [C, H, W]\n",
    "    \"\"\"\n",
    "    ################################################################################\n",
    "    # TODO: 데이터로더가 가져온 데이터셋 내 이미지(`img`)를 입력 받아 transform되었던      #\n",
    "    # 형태를 다시 되돌리고, 이를 화면에 출력한다.                                        #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    # 1) [-1, -1] 범위로 normalize된 데이터를 [0,1] 범위로 unnormalize\n",
    "    # 2) Tensor형인 이미지를 numpy 배열로 변환\n",
    "    # 3) [Channel, Hight, Width] 순서의 축을 [Hight, Width, Channel] 순서로 변경\n",
    "    # 4) matplotlib의 plt.imshow() 함수로 시각화\n",
    "\n",
    "    \"\"\"Write your code\"\"\"\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드로 데이터셋 및 데이터로더를 불러오고, `visualize()` 함수를 테스트해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 및 configuration 설정\n",
    "config = Config()\n",
    "\n",
    "# 이미지 데이터의 transform 정의하기\n",
    "transform = get_transform()\n",
    "\n",
    "# 데이터로더 불러오기\n",
    "train_loader, val_loader, test_loader = make_dataloader(\n",
    "    dataset_path=config.dataset_path,\n",
    "    batch_size=config.batch_size,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# 데이터셋의 하나를 뽑아 시각화 함수 사용해보기\n",
    "images, labels = next(iter(train_loader))\n",
    "visualize(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 구조로 TwoLayerFC 모델과, 해당 모델의 forward 연산을 정의하겠습니다.\n",
    "\n",
    "- Linear Layer: 이미지를 flatten 할 레이어\n",
    "- Fully Connected Layer 모듈\n",
    "    - FC1: input data -> hidden feature\n",
    "    - ReLU\n",
    "    - FC2: hidden feature -> output (각 클래스 별 classification 점수)\n",
    "\n",
    "`nn.Module` 을 상속받은 `TwoLayerFC` 모델의 `__init__` 함수에 모델 레이어를, `forward` 함수에 forward 연산을 정의하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-2: TwoLayerFC 모델 구성하기                                          #\n",
    "############################################################################\n",
    "\n",
    "class TwoLayerFC(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, num_class):\n",
    "        \"\"\"\n",
    "        Define model layers and initialize model weights\n",
    "\n",
    "        Args:\n",
    "            input_size  (int): dimension of input data\n",
    "            hidden_dim (int): dimension of hidden state\n",
    "            num_class (int): the number of data classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        ################################################################################\n",
    "        # TODO: 조건에 맞게 모델의 레이어를 정의함                                          #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # 1) 이미지를 flatten 할 Linear layer 정의\n",
    "        # 2) 두 개의 FC layer와 그 사이를 잇는 ReLU 활성화함수를 nn.Sequential로 묶어서 하나의 모듈로 정의\n",
    "        #    - 첫 번째 FC: input data -> hidden feature \n",
    "        #    - ReLU activation function\n",
    "        #    - 두 번째 FC: hidden feature -> output (각 클래스 별 classification 점수)\n",
    "\n",
    "        # 이미지를 flatten할 레이어 정의\n",
    "        self.flatten = \"\"\"Write your code\"\"\"\n",
    "        # 두 fully connected layer 정의 & Sequential로 묶기\n",
    "        self.linear_block = nn.Sequential(\n",
    "            \"\"\"Write your code\"\"\"\n",
    "        )\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of network\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data (shape - [B, C, H, W])\n",
    "        Returns:\n",
    "            torch.Tensor:\n",
    "                Results of forward pass which are classification scores\n",
    "                of each data for each class. (shape - [B, num_class])\n",
    "        \"\"\"\n",
    "        ################################################################################\n",
    "        # TODO: __init__에서 정의한 레이어 및 모듈을 활용하여 이미지가 각 클래스 별 점수로 나오는 #\n",
    "        # 연산을 수행함                                                                  #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # 1) 이미지를 flatten하기\n",
    "        # 2) FC, ReLU, FC를 거쳐 최종 출력(각 클래스 별 classification 점수)인 리턴값을 구하기\n",
    "\n",
    "        \"\"\"Write your code\"\"\"\n",
    "        \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 선언하고 레이어의 구성, 모델의 파라미터를 확인하는 방법은 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 선언하기\n",
    "model = TwoLayerFC(\n",
    "    input_size = config.mlp_input_size,\n",
    "    hidden_dim = config.mlp_hidden_dim,\n",
    "    num_class  = config.num_classes,\n",
    ")\n",
    "\n",
    "# 모델의 레이어 구성 확인하기\n",
    "print(model)\n",
    "\n",
    "# 모델의 파라미터 확인하기\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}\\nSize: {param.size()}\\nValues : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 학습과정 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습하는 `train()` 함수를 구현해봅시다. 모델의 가중치가 업데이트되는 학습 과정은 아래와 같이 이루어집니다.\n",
    "\n",
    "- Optimizer 초기화: 우리가 조정(학습)하려는 모델의 파라미터를 전달합니다.\n",
    "- 학습 loop 내에서\n",
    "    - `optimizer.zero_grad()`으로 모델 파라미터의 그래디언트를 리셋합니다.\n",
    "    - model output 및 loss 계산\n",
    "    - `loss.backward()`로 backpropagation합니다. PyTorch에서 자동적으로 각 파라미터에 대해 그래디언트를 계산해 저장합니다.\n",
    "    - `optimizer.step()`으로 위에서 계산한 그래디언트를 이용해 파라미터를 업데이트합니다.\n",
    "\n",
    "`train()` 함수에서는 학습 loop 내의 내용을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-3: 모델을 학습시키는 train() 함수 구현하기                              #\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, device, log_interval=50):\n",
    "    model.train() # 모델을 train 모드로 설정합니다.\n",
    "\n",
    "    for step, data in enumerate(train_loader): # 각 데이터 배치로 각 step을 학습\n",
    "        ################################################################################\n",
    "        # TODO: 데이터 배치 하나를 처리하는 train 프로세스를 구현함. Optimizer에서 gradient를  #\n",
    "        # 초기화하고, 데이터를 불러오며, 모델의 예측값을 얻고, 정답 값과 차이를 구해 loss로 삼음.  #\n",
    "        # loss를 backpropagation하고 네트워크의 가중치를 업데이트함.                         #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # 1) Optimizer `optimizer`의 gradient 값을 초기화\n",
    "        # 2) 배치 내 데이터를 불러오고 `device`로 데이터가 올라갈 디바이스를 지정함\n",
    "        # 3) Forward pass를 통해 모델의 출력(예측값)을 생성함\n",
    "        # 4) cross entropy loss를 계산함\n",
    "        # 5) Loss를 backpropagation하여 gradient를 전달함\n",
    "        # 6) optimizer로 네트워크 가중치를 업데이트함\n",
    "        # 7) [Optional] 로깅 용으로 loss를 출력함\n",
    "\n",
    "        \"\"\"Write your code\"\"\"\n",
    "\n",
    "        # [Optional] 로깅 용으로 loss를 출력함\n",
    "        if step % log_interval == 0:\n",
    "            print(f\"Step {step} / {len(train_loader)-1} | Loss {loss.item():.4f}\")\n",
    "        \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "## 4. 모델 테스트 과정 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습한 모델의 정확도(성능)을 측정하는 `test()` 함수를 구현합니다. `train()`과 유사하지만 크게는 아래 두 요소가 다릅니다.\n",
    "\n",
    "- 모델의 모드 변경: train이 아닌 eval 모드\n",
    "- Gradient 계산/저장 안 함: `torch.no_grad()`나 `@torch.no_grad()`를 통해 그래디언트 계산을 막습니다. Test에선 불필요하기 때문입니다.\n",
    "- 성능 측정: accuracy (=맞은 개수/전체 개수)를 계산하여 모델의 성능을 측정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-4: 모델을 평가하는 test() 함수 구현하기                                #\n",
    "############################################################################\n",
    "\n",
    "def test(model, dataloader, device, mode=\"val\"):\n",
    "    ################################################################################\n",
    "    # TODO: 실제 클래스를 모델의 예측이 얼마나 잘 맞추었는지 accuracy를 측정함             #\n",
    "    # 전체 validation/test set을 돌면서 맞춘 개수를 누적해서 더하고, 전체 개수로 나누어     #\n",
    "    # accuracy를 측정할 수 있음. 한 배치에 대한 처리 과정을 구현함.                       #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    # 1) 배치 내 데이터를 불러오고 `device`로 데이터가 올라갈 디바이스를 지정함\n",
    "    # 2) Forward pass를 통해 모델의 출력(예측값)을 생성함\n",
    "    # 3) `mode`가 validation(`val`)일 때는 loss 값을 계산함\n",
    "    # 4) 예측한 클래스를 추출함(top-1). 예측값이 각 클래스의 점수이므로, 값이 최대인 클래스를 찾음\n",
    "    # 5) 정답을 맞춘 개수를 누적합함\n",
    "    # 6) Accurcy를 계산함\n",
    "    \n",
    "    cnt_correct = 0 # 전체 셋 중 정답을 맞춘 개수\n",
    "    tot_num = len(dataloader.dataset) # 전체 개수\n",
    "    tot_loss = 0 # loss 총합\n",
    "\n",
    "    model.eval() # 모델을 eval 모드로 전환. Batch Normalization을 수행하지 않는 등 필요 없는 작업을 자동으로 끔.\n",
    "\n",
    "    with torch.no_grad(): # gradient 계산을 하지 않음.\n",
    "        for step, data in enumerate(dataloader): # 각 데이터 배치로 각 step을 학습\n",
    "            # 배치 내 데이터를 불러오고 `device`로 데이터가 올라갈 디바이스를 지정함\n",
    "            \"\"\"Write your code\"\"\"\n",
    "\n",
    "            # Forward pass를 통해 모델의 출력(예측값)을 생성함\n",
    "            \"\"\"Write your code\"\"\"\n",
    "\n",
    "            # `mode`가 validation(`val`)일 때는 loss 값을 계산함\n",
    "            if mode == \"val\":\n",
    "                \"\"\"Write your code\"\"\"\n",
    "\n",
    "            # 예측한 클래스를 추출함(top-1). 예측값이 각 클래스의 점수이므로, 값이 최대인 클래스를 찾음\n",
    "            \"\"\"Write your code\"\"\"\n",
    "\n",
    "            # 정답을 맞춘 개수를 누적합함\n",
    "            \"\"\"Write your code\"\"\"\n",
    "\n",
    "        # Accurcy를 계산함\n",
    "        \"\"\"Write your code\"\"\"\n",
    "\n",
    "        # 결과를 출력함\n",
    "        print(\"-\"*30)\n",
    "        if mode == \"val\":\n",
    "            print(f\"Validation Loss: {tot_loss.item()/len(dataloader):.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f} ({cnt_correct} / {tot_num})\")\n",
    "        print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 학습 진행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 <Req 2-1 ~ 2-4>의 내용을 상기하며 모델의 학습 전체 프로세스를 실행하고, 실제 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-5: 모델 학습 진행하기                                                 #\n",
    "############################################################################\n",
    "\n",
    "################################################################################\n",
    "# TODO: 학습에 사용할 설정값을 불러오고, 데이터셋 및 데이터로더를 불러오며,              #\n",
    "# 모델 및 optimizer을 선언하고, 학습 iteration을 수행하는 과정을 구현함.              #\n",
    "# 앞서 각 단계를 구현해두었으므로, 이를 종합하여 실행하는 단계임.                       #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# 1) 실행 디바이스 및 configuration 설정\n",
    "# 2) 이미지 데이터의 transform 정의하기\n",
    "# 3) 데이터로더 불러오기\n",
    "# 4) 모델을 선언하기\n",
    "# 5) 모델을 GPU에 올리기 (연산을 GPU로 하기 위함)\n",
    "# 6) Optimizer 선언하기: SGD 사용\n",
    "# 7) epoch만큼 반복하며 학습-평가를 수행하기: 한 epoch에서 학습 - 평가 순으로 수행하기\n",
    "\n",
    "\"\"\"Write your code\"\"\"\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Network) 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ThreeLayerConvNet 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 구조로 ThreeLayerConvNet 모델과, 해당 모델의 forward 연산을 정의하겠습니다.\n",
    "\n",
    "- Convolution layer 1: 5x5 필터, 2 픽셀의 zero padding 사용\n",
    "- ReLU 활성화함수\n",
    "- Convolution layer 2: 3x3 필터, 1 픽셀의 zero padding 사용\n",
    "- ReLU 활성화함수\n",
    "- Fully connected layer: 각 클래스 별 classification 점수로 매핑할 레이어\n",
    "\n",
    "<Req 2-2>와 동일한 방법으로 __init__과 forward 함수를 작성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-6: ThreeLayerConvNet 모델 구성하기                                    #\n",
    "############################################################################\n",
    "\n",
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_class):\n",
    "        \"\"\"\n",
    "        Define model layers and initialize model weights\n",
    "\n",
    "        Args:\n",
    "            in_channel (int): number os channels of input data\n",
    "            channel_1 (int): output channels of first conv layer and input channels of second conv layer\n",
    "            channel_2 (int): output channels of second conv layer\n",
    "            num_class (int): the number of data classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        ################################################################################\n",
    "        # TODO: 조건에 맞게 모델의 레이어를 정의함                                          #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # 1) in_channel -> channel_1으로 가는 첫 번째 convolution layer 정의\n",
    "        # 2) channel_1 -> channel_2으로 가는 두 번째 convolution layer 정의\n",
    "        # 3) ReLU 활성화 함수 정의\n",
    "        # 4) hidden feature를 클래스 별 분류 점수로 바꿀 FC layer 정의\n",
    "\n",
    "        self.conv1 = \"\"\"Write your code\"\"\"\n",
    "        self.conv2 = \"\"\"Write your code\"\"\"\n",
    "        self.relu = \"\"\"Write your code\"\"\"\n",
    "        self.fc = \"\"\"Write your code\"\"\"\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define the forward pass of network\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input data (shape - [B, C, H, W])\n",
    "        Returns:\n",
    "            torch.Tensor:\n",
    "                Results of forward pass which are classification scores\n",
    "                of each data for each class. (shape - [B, num_class])\n",
    "        \"\"\"\n",
    "        ################################################################################\n",
    "        # TODO: __init__에서 정의한 레이어 및 모듈을 활용하여 이미지가 각 클래스 별 점수로 나오는 #\n",
    "        # 연산을 수행함                                                                  #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # 1) 입력 데이터를 Convolution layer 1, 2와 ReLU 레이어를 통과시키기\n",
    "        # 2) hidden features를 [batch크기, 각 feature 크기] 형태로 바꾸기\n",
    "        # 3) FC layer를 거쳐 최종 출력(각 클래스 별 classification 점수)인 리턴값을 구하기\n",
    "        \n",
    "        \"\"\"Write your code\"\"\"\n",
    "    \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 모델 학습 진행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 <Req 2-5>와 마찬가지로, ThreeLayerConvNet 모델의 학습 전체 프로세스를 실행하고, 실제 학습을 진행함. 데이터셋 및 데이터로더는 <Req 2-5>와 동일하게 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-7: 모델 학습 진행하기                                                 #\n",
    "############################################################################\n",
    "\n",
    "################################################################################\n",
    "# TODO: 학습에 사용할 설정값을 불러오고, 데이터셋 및 데이터로더를 불러오며,              #\n",
    "# 모델 및 optimizer을 선언하고, 학습 iteration을 수행하는 과정을 구현함.              #\n",
    "# 앞서 각 단계를 구현해두었으므로, 이를 종합하여 실행하는 단계임.                       #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# 1) 실행 디바이스 및 configuration 설정\n",
    "# 2) 이미지 데이터의 transform 정의하기\n",
    "# 3) 데이터로더 불러오기\n",
    "# 4) 모델을 선언하기\n",
    "# 5) 모델을 GPU에 올리기 (연산을 GPU로 하기 위함)\n",
    "# 6) Optimizer 선언하기: SGD 사용\n",
    "# 7) epoch만큼 반복하며 학습-평가를 수행하기: 한 epoch에서 학습 - 평가 순으로 수행하기\n",
    "\n",
    "\"\"\"Write your code\"\"\"\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 더 높은 정확도의 이미지 분류기 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자유롭게 자신만의 CNN 이미지 분류기 모델을 만들고, CIFAR-10 데이터셋으로 모델을 학습하여 10 에폭 내에서 정확도 70% 이상의 더 높은 성능을 달성합니다.\n",
    "\n",
    "대표적으로 변경하거나 추가해볼 수 있는 사항은 아래와 같음.\n",
    "- 모델 구조 (레이어의 구성): Convolution layer의 개수와 입출력 채널 차원 크기, 커널 크기, 패딩 종류 및 크기, pooling layer의 종류와 크기, Fully connected layer의 입력 채널 차원 및 층 개수 등\n",
    "- 최적화 기법: Adam, AdamW, SGD, RMSprop 등\n",
    "- 하이퍼파라미터: 배치 크기, 학습률(learning rate) 등\n",
    "- 정규화 (normalization): 배치 정규화, 레이어 정규화, 그룹 정규화 등\n",
    "- 활성화함수: ReLU, LeakyReLU, GELU, Sigmoid 등\n",
    "- 데이터 증강 (augmentation): 뒤집기(flip), 랜덤 자르기(random crop) 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# Req 2-8: 더 높은 정확도의 이미지 분류기 모델 만들기                            #\n",
    "############################################################################\n",
    "\n",
    "################################################################################\n",
    "# TODO: 모델이나 설정값 등 자유롭게 변경하여 이미지 분류기 학습 과정을 구현함            #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "\"\"\"Write your code\"\"\"\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
