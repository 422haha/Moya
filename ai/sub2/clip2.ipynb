{"cells":[{"cell_type":"markdown","metadata":{"id":"5gUMDNr-pCwD"},"source":["# 과제 목표\n","\n","1. 대규모 데이터로 미리 학습된 CLIP 모델로 이미지 혹은 텍스트의 CLIP feature를 추출하는 방법을 학습\n","2. CLIP 모델을 활용하여 추가 학습이 없는 제로샷 이미지 분류기 구현"]},{"cell_type":"markdown","metadata":{"id":"oDYVkQhVT5yH"},"source":["# 환경 세팅"]},{"cell_type":"markdown","metadata":{},"source":["본 실습에서 사용할 라이브러리를 import 하겠습니다. Colab을 사용할 경우, 아래 명령어로 CLIP을 추가 설치해주세요."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Colab 사용 시\n","!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9779,"status":"ok","timestamp":1718212918224,"user":{"displayName":"한은기","userId":"13693550981734959354"},"user_tz":-540},"id":"yXPbd-Qbxe69"},"outputs":[],"source":["import random\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import clip"]},{"cell_type":"markdown","metadata":{},"source":["# CLIP으로 제로샷 이미지 분류기 만들기"]},{"cell_type":"markdown","metadata":{},"source":["CLIP 활용의 실습으로, 기학습된 CLIP 모델로 이미지 분류기를 따로 학습하지 않고도 이미지 분류를 수행해보겠습니다."]},{"cell_type":"markdown","metadata":{},"source":["본 실습에 사용할 설정값을 지정하겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","cifar100_dataset_path = './datasets'"]},{"cell_type":"markdown","metadata":{},"source":["본 실습에서는 huggingface에서 제공하는 CLIP 모델을 사용합니다. 사용 예시와 다양한 모델에 대한 docs는 아래 링크를 참조해주세요!\n","\n","https://huggingface.co/docs/transformers/model_doc/clip"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# CLIP 모델 및 이미지 프로세서 불러오기\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)"]},{"cell_type":"markdown","metadata":{},"source":["데이터셋은 SUB PJT 1에서 사용한 CIFAR-10보다 더 클래스가 많은 CIFAR-100 데이터셋을 사용하겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load dataset\n","dataset = torchvision.datasets.CIFAR100(\n","    cifar100_dataset_path, train=False, download=True,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 1. 라벨 텍스트 토큰화하기"]},{"cell_type":"markdown","metadata":{"id":"FQa1qiwtY2Rl"},"source":["텍스트(라벨)의 CLIP feature를 얻기 위해선 텍스트를 토큰화해야 합니다. \"a photo of a {LABEL}\" 형식으로 CIFAR-100 데이터셋의 라벨 정보를 토큰화하여 리스트로 저장합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7450,"status":"ok","timestamp":1718213126482,"user":{"displayName":"한은기","userId":"13693550981734959354"},"user_tz":-540},"id":"FOBLXVWuMUi3","outputId":"6b2595f2-52fc-4388-ae4f-cc927ef290c1"},"outputs":[],"source":["############################################################################\n","# Req 2-1: 라벨 텍스트 토큰화하기                                              #\n","############################################################################\n","\n","################################################################################\n","# TODO: 데이터셋 내 라벨을 이용하여 이미지를 설명하는 텍스트를 만들고, 각 텍스트의        #\n","# 토큰화를 진행함                                                                 #\n","################################################################################\n","# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","# 1) 데이터셋 내 클래스(라벨)을 리스트화함\n","# 2) 클래스(라벨)을 이용하여 \"a photo of a {LABEL}\" 형태의 텍스트를 tokenize함\n","\n","\n","# 데이터셋 내 클래스(라벨)을 리스트화함\n","labels = \"\"\"Write your code\"\"\"\n","\n","# 클래스(라벨)을 이용하여 \"a photo of a {LABEL}\" 형태의 텍스트를 tokenize함\n","text_inputs = \"\"\"Write your code\"\"\"\n","text_inputs = torch.cat(text_inputs).to(device)\n","\n","print(f\"Number of labels: {len(text_inputs)}\")\n","print(\"Result of tokenization (for random 3 labels)\")\n","random_text = random.sample(list(text_inputs), 3)\n","for i in range(len(random_text)):\n","    print(random_text[i])"]},{"cell_type":"markdown","metadata":{},"source":["## 2. 이미지와 라벨 텍스트 간 CLIP feature 유사도 계산하기\n","\n","이미지 클래스(라벨)의 CLIP text feature와 분류 대상의 입력 이미지의 CLIP image features 간 top-K 유사도를 구하는 함수를 작성하겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1718213113357,"user":{"displayName":"한은기","userId":"13693550981734959354"},"user_tz":-540},"id":"_zfEbQHjPUSu"},"outputs":[],"source":["############################################################################\n","# Req 2-2: 이미지와 라벨 텍스트 간 유사도 계산하기                               #\n","############################################################################\n","\n","def calc_similarities(image, text_inputs, topk):\n","    \"\"\"Calulate cosine similarities between image features and text features.\n","\n","    Args:\n","        image (torch.Tensor): Image to classify the label\n","        text_inputs (torch.Tensor): Tokenized texts containing label information\n","        topk (int): How many indices (classes) to extract as an answer\n","    Returns:\n","        top_sim_scores (torch.Tensor): Top-K similarity scores\n","        top_indices (torch.Tensor): Top-K indices (order of nubmers matched with `top_sim_scores`)\n","    \"\"\"\n","    ################################################################################\n","    # TODO: 이미지를 텐서화하고, 그리드를 이용하여 k 개의 이미지를 한 번에 나타냄            #\n","    ################################################################################\n","    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    # 1) 이미지를 CLIP 전처리를 통하여 전처리함\n","    # 2) 라벨 정보를 담은 텍스트와 입력 이미지 각각의 CLIP feature를 구함\n","    # 3) Image feature와 text feature의 코사인 유사도를 구함\n","    # 4) 코사인 유사도에 softmax를 취하여 총합을 1로 만듦\n","    # 5) Top-K 값과 이에 해당하는 인덱스를 추출함\n","\n","    \"\"\"Write your code\"\"\"\n","\n","    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n","    ################################################################################\n","    #                                 END OF YOUR CODE                             #\n","    ################################################################################\n","\n","    return top_sim_scores, top_indices"]},{"cell_type":"markdown","metadata":{"id":"tcwr1-G4Zb_R"},"source":["아래 코드로 `calc_similarities` 함수를 테스트할 수 있습니다.\n","\n","이미지 분류를 테스트할 대상 이미지를 무작위로 선택하고, 몇 개의 분류 예측을 뽑을 것인지 Top-K 숫자도 지정합니다. 이후 `calc_similarities` 함수를 이용하여 예측 결과를 확인합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1718213127082,"user":{"displayName":"한은기","userId":"13693550981734959354"},"user_tz":-540},"id":"kk6CSljZTdk-","outputId":"e0be50c3-4baf-4881-da07-2d3f7c3f8c1a"},"outputs":[],"source":["# Select random image from dataset\n","image_idx = random.randint(0, len(dataset))\n","image, label_idx = dataset[image_idx]\n","\n","# Draw image\n","plt.figure(figsize=(2, 2))\n","plt.imshow(image)\n","\n","# Select K to show Top-K classification result\n","K = 10\n","\n","# Calculate the similarites between image and labels\n","# and classify the image with similarity scores\n","sim_scores, indices = calc_similarities(image, text_inputs, K)\n","\n","print(f\"Label (answer): {dataset.classes[label_idx]}\\n\")\n","print(f\"Top {K} Classification Results:\")\n","for score, idx in zip(sim_scores, indices):\n","    print(f\"{dataset.classes[idx]:15s}: {score.item()*100:.2f}%\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
